This repository contains the MCNet-DL framework for unsupervised single-image super-resolution of hyperspectral remote sensing data using synthetic abundance maps, as introduced in our paper *“Synthetic Abundance Maps for Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images”* by X. Xu, Y. Gousseau, C. Kervazo, and S. Ladjal (Télécom Paris, Institut Polytechnique de Paris).  

## Overview

MCNet-DL builds on the Mixed 2D/3D Convolutional Network (MCNet) originally proposed by Li et al. for hyperspectral image super-resolution.  
- Original MCNet repository: https://github.com/qianngli/MCNet/tree/master  
- Reference: Li, Q., Wang, Q., & Li, X. (2020). *Mixed 2D/3D convolutional network for hyperspectral image super-resolution*. Remote Sensing, 12(10), 1660.

In this project, MCNet is adapted to operate on synthetic abundance maps derived from a given hyperspectral image, enabling unsupervised training without paired high-resolution hyperspectral data.

## Requirements

The original implementation was developed with:
- Python 2.7  
- PyTorch 0.3.1  
- CUDA 9.0  

If you port the code to a more recent environment, make sure to update all dependencies consistently (PyTorch, CUDA, and any auxiliary libraries).

## Minimum-Volume NMF

The pre-processing stage relies on Minimum-Volume Nonnegative Matrix Factorization (MinVol NMF) to estimate the spectral endmembers from the low-resolution hyperspectral image. The method is based on:

- Leplat, V., Ang, A. M., & Gillis, N. (2019). *Minimum-volume rank-deficient nonnegative matrix factorizations*. ICASSP 2019, pp. 3402–3406, IEEE.  
- Official MinVol NMF code and documentation:  
  https://sites.google.com/site/nicolasgillis/code#h.p_ID_98  

Workflow:
1. The original HSI is reshaped into a 2D matrix and factorized by MinVol NMF to obtain:
   - Endmember matrix \(S\) (spectral signatures)
   - Abundance matrix \(A\) (per-pixel coefficients)
2. Abundances are then refined using a linear least-squares fit between the original HSI and the MinVol endmembers.

These abundance maps form the basis for the subsequent synthetic dataset generation.

## Dataset Creation

Once endmembers and abundances have been estimated, synthetic training data are generated by simulating low- and high-resolution abundance maps and their corresponding hyperspectral observations.  

To create the synthetic dataset used by MCNet-DL, run:

```.
python ./SISR-DL/Dataset_DL_Generator.py
```

This script:
- Creates paired low- and high-resolution samples.
- Stores them in a format compatible with the training and validation loaders in this repository.

## Training

After generating the synthetic dataset, train the MCNet-DL super-resolution network with:

```
python ./SISR-DL/Train.py
```

The training script:
- Loads the synthetic training and validation sets.
- Instantiates the modified MCNet model configured for abundance-based input.
- Optimizes the network parameters using an L1 loss on the abundance or reconstructed HSI domain (depending on your configuration).
- Periodically saves model checkpoints and logs training/validation metrics.

## Testing

To evaluate a trained model on the synthetic or real hyperspectral data, run:

```.
python ./SISR-DL/Test.py
```

The testing script:
- Loads the trained MCNet-DL checkpoint.
- Applies the network to the test abundance maps or low-resolution HSI-derived inputs.
- Reconstructs super-resolved hyperspectral images from the predicted abundances and the MinVol endmembers.
- Computes quantitative metrics such as PSNR and can optionally save reconstructed images or cubes.

## End-to-End Pipeline Summary

Conceptually, the complete workflow is:

1. **Pre-processing of the original HSI**  
   - Apply MinVol NMF (Gillis et al.) to estimate spectral endmembers.  
   - Recover abundance maps by linear least squares using the original HSI and MinVol endmembers.

2. **Synthetic dataset generation**  
   - Use `Dataset_DL_Generator.py` to generate synthetic low- and high-resolution abundance/HSI pairs.

3. **Training**  
   - Train MCNet-DL on the synthetic dataset via `Train.py`.

4. **Testing**  
   - Evaluate the trained model on test data via `Test.py`, reconstructing super-resolved HSI from predicted abundances and the fixed endmembers.

This design enables unsupervised hyperspectral super-resolution using only a single real HSI and a physically motivated synthetic data generator based on spectral unmixing.
## Overview

MCNet-DL builds on the Mixed 2D/3D Convolutional Network (MCNet) originally proposed by Li et al. for hyperspectral image super-resolution.  
- Original MCNet repository: https://github.com/qianngli/MCNet/tree/master  
- Reference: Li, Q., Wang, Q., & Li, X. (2020). *Mixed 2D/3D convolutional network for hyperspectral image super-resolution*. Remote Sensing, 12(10), 1660.

In this project, MCNet is adapted to operate on synthetic abundance maps derived from a given hyperspectral image, enabling unsupervised training without paired high-resolution hyperspectral data.

## Requirements

The original implementation was developed with:
- Python 2.7  
- PyTorch 0.3.1  
- CUDA 9.0  

If you port the code to a more recent environment, make sure to update all dependencies consistently (PyTorch, CUDA, and any auxiliary libraries).

## Minimum-Volume NMF

The pre-processing stage relies on Minimum-Volume Nonnegative Matrix Factorization (MinVol NMF) to estimate the spectral endmembers from the low-resolution hyperspectral image. The method is based on:

- Leplat, V., Ang, A. M., & Gillis, N. (2019). *Minimum-volume rank-deficient nonnegative matrix factorizations*. ICASSP 2019, pp. 3402–3406, IEEE.  
- Official MinVol NMF code and documentation:  
  https://sites.google.com/site/nicolasgillis/code#h.p_ID_98  

Workflow:
1. The original HSI is reshaped into a 2D matrix and factorized by MinVol NMF to obtain:
   - Endmember matrix \(S\) (spectral signatures)
   - Abundance matrix \(A\) (per-pixel coefficients)
2. Abundances are then refined using a linear least-squares fit between the original HSI and the MinVol endmembers.

These abundance maps form the basis for the subsequent synthetic dataset generation.

## Dataset Creation

Once endmembers and abundances have been estimated, synthetic training data are generated by simulating low- and high-resolution abundance maps and their corresponding hyperspectral observations.  

To create the synthetic dataset used by MCNet-DL, run:

```.
python ./SISR-DL/Dataset_DL_Generator.py
```

This script:
- Creates paired low- and high-resolution samples.
- Stores them in a format compatible with the training and validation loaders in this repository.

## Training

After generating the synthetic dataset, train the MCNet-DL super-resolution network with:

```
python ./SISR-DL/Train.py
```

The training script:
- Loads the synthetic training and validation sets.
- Instantiates the modified MCNet model configured for abundance-based input.
- Optimizes the network parameters using an L1 loss on the abundance or reconstructed HSI domain (depending on your configuration).
- Periodically saves model checkpoints and logs training/validation metrics.

## Testing

To evaluate a trained model on the synthetic or real hyperspectral data, run:

```.
python ./SISR-DL/Test.py
```

The testing script:
- Loads the trained MCNet-DL checkpoint.
- Applies the network to the test abundance maps or low-resolution HSI-derived inputs.
- Reconstructs super-resolved hyperspectral images from the predicted abundances and the MinVol endmembers.
- Computes quantitative metrics such as PSNR and can optionally save reconstructed images or cubes.

## End-to-End Pipeline Summary

Conceptually, the complete workflow is:

1. **Pre-processing of the original HSI**  
   - Apply MinVol NMF (Gillis et al.) to estimate spectral endmembers.  
   - Recover abundance maps by linear least squares using the original HSI and MinVol endmembers.

2. **Synthetic dataset generation**  
   - Use `Dataset_DL_Generator.py` to generate synthetic low- and high-resolution abundance/HSI pairs.

3. **Training**  
   - Train MCNet-DL on the synthetic dataset via `Train.py`.

4. **Testing**  
   - Evaluate the trained model on test data via `Test.py`, reconstructing super-resolved HSI from predicted abundances and the fixed endmembers.

This design enables unsupervised hyperspectral super-resolution using only a single real HSI and a physically motivated synthetic data generator based on spectral unmixing.

If you use this code in your research, please cite:  

```.
@unpublished{xu:hal-05483496,
  TITLE = {{Synthetic Abundance Maps for Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images}},
  AUTHOR = {Xu, Xinxin and Gousseau, Yann and Kervazo, Christophe and Ladjal, Sa{\"i}d},
  URL = {https://telecom-paris.hal.science/hal-05483496},
  NOTE = {working paper or preprint},
  YEAR = {2025},
  MONTH = Oct,
  KEYWORDS = {Hyperspectral image ; Remote sensing ; Super-resolution ; Unsupervised learning ; Synthetic training data},
  PDF = {https://telecom-paris.hal.science/hal-05483496v1/file/MAIN.pdf},
  HAL_ID = {hal-05483496},
  HAL_VERSION = {v1},
}
```
